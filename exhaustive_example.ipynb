{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# don't forget the most important one :)\n",
    "import otpsy as ot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data simulation\n",
    "Consider conducting a research study aimed at investigating the impact of art exposition on the visual perception of angry facial expressions in 50 participants. In this context, variables could include the **duration (ms)** of exploration of the painting scene, **behavioral performance** (accuracy and RT) in discriminating between angry and happy faces, and **scores** related to depression. Subsequently, there is a desire to implement control for various factors in the analysis:\n",
    "\n",
    "* Does the participant look at the painting scene during the art exposition?\n",
    "* Is the participant realising the task properly? (fatigue, lack of motivation,...)\n",
    "* Exclusion of participants with excessively high depression scores (>12)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the result reproducible\n",
    "rng = np.random.default_rng(seed=22404)\n",
    "NB_PART = 60 # number of participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# art exposition\n",
    "art_looking_time = rng.normal(loc=2000, scale=400, size=NB_PART)\n",
    "\n",
    "# discrimination task\n",
    "discrimination_performance = rng.normal(loc=0.9, scale=0.05, size=NB_PART)\n",
    "discrimination_time = rng.normal(loc=400, scale=100,size=NB_PART)\n",
    "\n",
    "# questionnaire\n",
    "depression_score = rng.normal(loc=2, scale = 2, size=NB_PART)\n",
    "gender = [\"M\"  if i%2 == 0 else \"W\" for i in range(1, 61)]\n",
    "age = rng.normal(loc=30, scale = 4, size=NB_PART)\n",
    "random_col = rng.normal(loc=20, scale = 2, size=NB_PART)\n",
    "index_participant = [f\"P{i}\" for i in range(1, 61)]\n",
    "likert1 = rng.integers(low = 1, high = 7, size = NB_PART)\n",
    "likert2 = rng.integers(low = 1, high = 7, size = NB_PART)\n",
    "likert3 = rng.integers(low = 1, high = 7, size = NB_PART)\n",
    "likert4 = rng.integers(low = 1, high = 7, size = NB_PART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce some abberation in data\n",
    "art_looking_time[9:11] = 200 # participants 10 and 11 didn't look at the painting scene (only 200 ms of exploration time)\n",
    "discrimination_performance[36] = 0.51 # participant 36's discrimination score is near chance level\n",
    "discrimination_time[36] = 95 # participant 36's mean response time is way too short relatively to human ability\n",
    "depression_score[4] = 21 # participant 4 has a high depression score (above 12)\n",
    "likert1[3] = likert2[3] = likert3[3] = likert4[3] = 1 # Same answer for the 4 items likert (despite inverted items)\n",
    "likert1[5] = likert2[5] = likert3[5] = likert4[5] = 7 # Same answer for the 4 items likert (despite inverted items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"index_participant\":index_participant,\n",
    "    \"gender\": gender,\n",
    "    \"age\": age,\n",
    "    \"random_col\": random_col,\n",
    "    'art_looking_time':art_looking_time,\n",
    "    'discrimination_performance': discrimination_performance,\n",
    "    'discrimination_time':discrimination_time,\n",
    "    'depression_score': depression_score,\n",
    "    'likert1': likert1,\n",
    "    'likert2': likert2,\n",
    "    'likert3': likert3,\n",
    "    'likert4': likert4,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./tests/data.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to define a sample object to specify which columns you want to apply a specific method to. You have to specify one sample for each planned method you want to apply. For *art looking time*, *discrimination performance*, and *discrimination time*, we can use continuous but robust methods like IQR or MAD. For this purpose, we create a sample object to visualize the columns to test and apply the method afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ot.Sample(df=df,\n",
    "                   columns_to_test=[\"art_looking_time\", \n",
    "                                   \"discrimination_performance\", \n",
    "                                   \"discrimination_time\"],\n",
    "                   participant_column=\"index_participant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dash() got an unexpected keyword argument 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Visualise the data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive - KU Leuven\\Documents\\otpsy\\src\\otpsy\\main.py:125\u001b[0m, in \u001b[0;36mSample.visualise\u001b[1;34m(self, column)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     column_to_vis \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39m_process_column_to_test(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf, column)\n\u001b[1;32m--> 125\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_to_vis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive - KU Leuven\\Documents\\otpsy\\src\\otpsy\\visualise\\app.py:55\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(df, column_to_vis)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(df, column_to_vis):\n\u001b[1;32m---> 55\u001b[0m     app \u001b[38;5;241m=\u001b[39m \u001b[43mdash\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDash\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexternal_stylesheets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdbc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthemes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDARKLY\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# set app layout\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     list_of_method \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIQR\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrSD\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     58\u001b[0m     list_of_method_2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTukey\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Workdir\\MyApps\\Python\\Python310\\lib\\site-packages\\dash\\dash.py:427\u001b[0m, in \u001b[0;36mDash.__init__\u001b[1;34m(self, name, server, assets_folder, pages_folder, use_pages, assets_url_path, assets_ignore, assets_external_path, eager_loading, include_assets_files, include_pages_meta, url_base_pathname, requests_pathname_prefix, routes_pathname_prefix, serve_locally, compress, meta_tags, index_string, external_scripts, external_stylesheets, suppress_callback_exceptions, prevent_initial_callbacks, show_undo_redo, extra_hot_reload_paths, plugins, title, update_title, long_callback_manager, background_callback_manager, add_log_handler, hooks, routing_callback_inputs, description, on_error, **obsolete)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(  \u001b[38;5;66;03m# pylint: disable=too-many-statements\u001b[39;00m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    387\u001b[0m     name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mobsolete,\n\u001b[0;32m    426\u001b[0m ):\n\u001b[1;32m--> 427\u001b[0m     \u001b[43m_validate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_obsolete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobsolete\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m     caller_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;28;01melse\u001b[39;00m get_caller_name()\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;66;03m# We have 3 cases: server is either True (we create the server), False\u001b[39;00m\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;66;03m# (defer server creation) or a Flask app instance (we use their server)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Workdir\\MyApps\\Python\\Python310\\lib\\site-packages\\dash\\_validate.py:368\u001b[0m, in \u001b[0;36mcheck_obsolete\u001b[1;34m(kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;66;03m# any other kwarg mimic the built-in exception\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDash() got an unexpected keyword argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Dash() got an unexpected keyword argument 'mode'"
     ]
    }
   ],
   "source": [
    "# Visualise the data\n",
    "sample.visualise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = sample.method_MAD(distance = 2.5)\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To obtain more details about the different values\n",
    "print(outliers.inspect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, outliers that we introduce are spotted with median absolute distance method.\n",
    "In an interesting manner, we can see the P37 has really low performance, associated with a low reaction time. We can suggest that he didn't realise the task properly.   \n",
    "We could remove then now, but we want to take into account too high level of depression. Thus, we can create another outliers object that we will concatenate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_depression = ot.Sample(\n",
    "    df,\n",
    "    \"depression_score\",\n",
    "    \"index_participant\"\n",
    ").method_cutoff(\n",
    "    high_threshold=12,\n",
    "    threshold_included=False)\n",
    "print(outliers_depression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat both object\n",
    "final_outliers_object = ot.concat([outliers, outliers_depression])\n",
    "print(final_outliers_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, one participant (P44) has reported that he understood your hypothesis and acted in a way to confirm it. You decide to exclude him. You can simply add it to the outliers object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_outliers_object.add(\"P44\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we would have consider an outliers as not being \"really an outliers\", it is possible to remove them with the method `.remove()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_outliers_object.remove(\"P1\")\n",
    "# obj.remove([\"P1\", \"P2\"]) if you want to remove more than one outlier\n",
    "# obj.remove({\"Col1\": \"P1\"}) if you want to remove an outlier on a specific column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can obtain your dataframe without outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = final_outliers_object.manage(\"delete\")\n",
    "# \"na\" if you want to replace aberrant values with missing values\n",
    "# \"winsorise\" if you want to replace aberrant values with the threshold."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
